---
title: "Text Mining Project - M2 Data Mining"
author: "FOSSIER Camille - NEBBACHE Nabih"
date: "20/12/2019"
output: html_document
---

# Visualisation du corpus

Ce document a pour objectif de visualiser un peu mieux les données du corpus en
utilisant les données du corpus enrichi et la modélisation des thématiques.

# Axes de visualisation

## Observation des thématiques

Regardons ce que contiennent les thématiques obtenues :

```{r}
source("functions.R")

topics = read.csv(topics_path)
corpus = read.csv(corpus_path,sep="\t", stringsAsFactors=F)

relevant_docs = relevant_topic_documents(topics, corpus$titles, 30)
relevant_docs
```

Les 4 topics enregistrés dans le csv sont donnés à titre d'exemple, mais il serait possible de refaire une extraction de thématiques
et de réutiliser les outils que nous allons voir par la suite pour mener d'autres analyses.

Essayons de nommer les 4 thématiques ci-dessus :

- Les deux premières semblent contenir beaucoup de noms de pays différents. La première semble toucher à des affaires militaires. Nous appellerons donc cette catégorie : Conflits internationaux. La seconde semble plus particulièrement toucher à de la politique, donc nous l'appellerons : Politique internationale.
- La troisième thématique semble toucher à des affaires judiciaires, en effet il est question de "Corrections", de "Fraude", d'"éthique",
et des mots comme "case" (affaire), "attorney" (avocat), "trial" (procès), confirment cette idée : Justice.
- Enfin la quatrième concerne de manière évidente des affaires soviétiques : URSS.

Choisissons une granularité trimestrielle pour observer les articles. Nous allons donc regarder l'évolution de la
probabilité d'observer une thématique dans le corpus à chaque trimestre. 

```{r}
dates = as.POSIXlt(corpus$dates)
dates = to_trimestrial_dates(dates)

topics_d = topics
topics_d$dates <- unlist(lapply(dates, format))


amounts = group_by_dates(topics_d,
               t1 = mean(V1),
               t2 = mean(V2),
               t3 = mean(V3),
               t4 = mean(V4))

num_dates = as.POSIXlt(amounts$dates)

plot(num_dates, amounts$t1, col=1, ylim=c(0,1), type="l")
lines(num_dates, amounts$t2, col=2, ylim=c(0,1))
lines(num_dates, amounts$t3, col=3, ylim=c(0,1))
lines(num_dates, amounts$t4, col=4, ylim=c(0,1))

legend("topright",
       col=(1:4),
       lty=1,
       cex=0.8,
       legend=c("Conflits internationaux",
                "Politique internationale",
                "Justice",
                "URSS"))

```

Entre 1987 et 1990 on observe une forte variation de l'importance du sujet 3.

Commençons par regarder l'évolution de cette thématique avec une granularité plus fine, par exemple par mois.

```{r}
filtered_dates = filter_dates(corpus$dates, date_min="1988-01-01", date_max="1990-01-01")
filtered_topics = topics[filtered_dates, 3]

dates = corpus$dates[filtered_dates]
dates = to_monthly_dates(as.POSIXlt(dates))

topics_d = data.frame("V3"=filtered_topics)
topics_d$dates <- unlist(lapply(dates, format))

amounts = group_by_dates(topics_d,
               t3 = mean(V3))

num_dates = as.POSIXlt(amounts$dates)

plot(num_dates, amounts$t3, col=3, ylim=c(0,1), type="l")

legend("topright",
       col=3,
       lty=1,
       cex=0.8,
       legend="Topic 3")

```

## Liens entre certaines entités

Essayons d'explorer les personnes et les lieux évoqués dans les articles de cette époque :

```{r}
# Reading extracted entities
entities = read.csv(entities_path)

# Only keeping the ones from the filtered dates
entities = entities[entities$doc_id %in% filtered_dates,]

# Generating matrices of apparition in documents for entities
entities_matrices = get_doc_matrices(entities)
persons = entities_matrices$PERSON

# Keeping persons that appear the most often
ord = order(rowSums(persons), decreasing = T)
small_pers = persons[ord[1:20],]

# Computing cooccurences of people with other people
cooc = small_pers %*% t(small_pers)

# Removing self cooccurences
for (i in 1:nrow(cooc)){
  cooc[i,i] = 0
}

# Plot
library(qgraph)
qgraph(cooc,
       layout="spring",
       vsize=6,
       labels=dimnames(persons)[[1]][ord[1:20]],
       arrows=F)

```

On remarque dans la partie supérieure de ce graphique qu'un ensemble de personnes semblent être étroitement reliées.
Effectuons une recherche dans nos articles pour en apprendre un peu plus sur ces personnes.

```{r}
iterator = get_iterator(corpus$texts)
vocabulary = get_vocabulary(iterator)
dtm = get_dtm(vocabulary, iterator)
result = search("koch dinkins myerson gabel capasso devincenzo",
       corpus,
       vocabulary,
       dtm)

corpus$titles[result]
corpus$texts[result[1]]
```

# Supplémentaire

## Recherche par entité

On va rechercher dans le texte en spécifiant si ce que nous cherchons est : une personne, un lieu ou un événement.
Le résultat de ces recherches nous renvoie tous les éléments de contexte autour de l'entité en question.

```{r}
ent_mat = load_entity_matrices()
search_entity("nixon", "PERSON",number_of_suggestions = 10, list_of_matrices = ent_mat)

```
On peut aussi spécifier une plage de dates. Le resultat change puisque il contextualisé par le temps.

```{r}
dates = corpus$dates
search_entity("nixon", "PERSON", number_of_suggestions = 10, list_of_matrices = ent_mat,list_of_dates = dates, date_min = "1991-01-01", date_max = "1999-01-01"  )
```

La même chose peut être faite pour les événements 
```{r}
search_entity("bolshevik", "EVENT",number_of_suggestions = 10, list_of_matrices = ent_mat)

```

